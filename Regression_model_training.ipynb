{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552215b4-738d-475c-84ee-9a45a23bdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from utils import MyTrainDataset\n",
    "from datetime import datetime\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd4e46f-abdd-4fb3-83fa-407fd4050b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, elements):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_files = os.listdir(data_dir)\n",
    "        self.data_files.sort()\n",
    "        if self.data_files[0].startswith('.'):\n",
    "            self.data_files.pop(0)\n",
    "        \n",
    "        self.elements = np.load(elements)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.data_dir + '/' + self.data_files[idx]) # (1920, 2560, 10)\n",
    "        data = data/255\n",
    "        data = np.transpose(data, (2, 0, 1))\n",
    "        elements = self.elements[idx]\n",
    "        elements = np.float32(elements)\n",
    "        return torch.tensor(data), torch.tensor(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64c69e7-4280-40f6-aec3-14335e9af790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1920, 2560])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset('EDS_predict_path', 'elements.npy')\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(dataset[0][0].shape)\n",
    "print(dataset[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90e0db3-9b4f-498a-99b5-b7d5ce21c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _get_layers(nn.Module):\n",
    "    def __init__(self, elements=7):\n",
    "        super().__init__()\n",
    "        self.elements = elements\n",
    "    def forward(self, x):\n",
    "        sem = x[:, :3, :, :]\n",
    "        c = x[:, 3, :, :]\n",
    "        c = c[:, None, :, :] \n",
    "        ca = x[:, 4, :, :]\n",
    "        ca = ca[:, None, :, :]\n",
    "        mg = x[:, 5, :, :]\n",
    "        mg = mg[:, None, :, :]\n",
    "        na = x[:, 6, :, :]\n",
    "        na = na[:, None, :, :]\n",
    "        o = x[:, 7, :, :]\n",
    "        o = o[:, None, :, :]\n",
    "        s = x[:, 8, :, :]\n",
    "        s = s[:, None, :, :]\n",
    "        cl = x[:, 9, :, :]\n",
    "        cl = cl[:, None, :, :]\n",
    "        return sem, c, ca, mg, na, o, s, cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522ec478-6463-43a4-b573-4d027e7677e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4356122d-1df4-40c2-83b8-389bc6016dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \n",
    "        bs = q.size(0)\n",
    "        # a = self.q_linear(q)\n",
    "        # print(a.shape)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # print(q.shape)\n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "       \n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        \n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
    "        \n",
    "        output = self.out(concat)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9daa3431-b63d-4f21-a0fb-39023b9e6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model = 158\n",
    "# heads = 2\n",
    "# x = torch.randn(8, 118, 158)\n",
    "# net = MultiHeadAttention(2, 158)\n",
    "# output = net(x, x, x)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f42487-3e89-41c1-a550-d9d09c5947b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
    "        super().__init__() \n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "# net = FeedForward(158)\n",
    "# x=torch.randn(10, 158)\n",
    "# y = net(x)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca1f76e4-eb50-4b01-ad33-a1bb14bde894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.size = d_model\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "    \n",
    "# net = Norm(158)\n",
    "# x=torch.randn(10, 158)\n",
    "# y = net(x\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0552a982-3dd2-46b0-99eb-f3d74dc4cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an encoder layer with one multi-head attention layer and one # feed-forward layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "# build a decoder layer with two multi-head attention layers and\n",
    "# one feed-forward layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "    def forward(self, x, e_outputs, src_mask=None, trg_mask=None):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x\n",
    "\n",
    "    # We can then build a convenient cloning function that can generate multiple layers:\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9013c7f7-abbb-4624-b8a3-4db1f0c52490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 300):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                \n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        return x\n",
    "\n",
    "# net = PositionalEncoder(282)\n",
    "# x = src = torch.randn(8, 211, 282)\n",
    "# y = net(x)\n",
    "# y.shape\n",
    "\n",
    "# net = PositionalEncoder(158)\n",
    "# x = src = torch.randn(8, 118, 158)\n",
    "# y = net(x)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b61527-3ff8-4b9c-86a4-adad4ee10aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        # self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, src, mask=None):\n",
    "        # x = self.embed(src)\n",
    "        x = src\n",
    "        # x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        # self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, trg, e_outputs, src_mask=None, trg_mask=None):\n",
    "        # x = self.embed(trg)\n",
    "        # x = self.pe(x)\n",
    "        x = trg\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e61689-ecc6-4b06-9ac1-52ed297ba612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
    "        self.reduce = nn.Linear(d_model, trg_vocab)\n",
    "        # self.reduce = nn.Linear(d_model, 1)\n",
    "        self.linear_1 = nn.Linear(trg_vocab*src_vocab, trg_vocab)\n",
    "        self.out = nn.Linear(56, 1)\n",
    "    def forward(self, src, trg, src_mask=None, trg_mask=None):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.reduce(d_output)\n",
    "        output = output.view(output.shape[0], -1)        \n",
    "        output = self.linear_1(output)\n",
    "        output = output.view(-1)\n",
    "        output = self.out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5476ffac-03cd-4d04-88c8-8db0cc9cf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 118\n",
    "trg_vocab = 7\n",
    "# t = Transformer(src_vocab, trg_vocab, 158, 3, 2)\n",
    "# src = torch.randn(8, 118, 158)\n",
    "# trg = torch.randn(8, 118, 158)\n",
    "# # t = t.to('cuda')\n",
    "# # src = src.to('cuda')\n",
    "# # trg = trg.to('cuda')\n",
    "# output = t(src, trg)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfb1e10f-2803-4bff-886c-2b3195aa232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _feature_extraction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_feature_extraction, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.conv1_sem = nn.Conv2d(3, 4, 5)\n",
    "        self.conv2_sem = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_c = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_c = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_ca = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_ca = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_mg = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_mg = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_na = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_na = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_o = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_o = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_s = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_s = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_cl = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_cl = nn.Conv2d(4, 8, 5)\n",
    "    def forward(self, sem, c, ca, mg, na, o, s, cl):\n",
    "        sem = self.pool(F.relu(self.conv1_sem(sem)))\n",
    "        sem = self.pool(F.relu(self.conv2_sem(sem))) #torch.Size([4, 8, 211, 282])\n",
    "        c = self.pool(F.relu(self.conv1_c(c)))\n",
    "        c = self.pool(F.relu(self.conv2_c(c))) #torch.Size([4, 8, 211, 282])\n",
    "        ca = self.pool(F.relu(self.conv1_ca(ca)))\n",
    "        ca = self.pool(F.relu(self.conv2_ca(ca))) #torch.Size([4, 8, 211, 282])\n",
    "        mg = self.pool(F.relu(self.conv1_mg(mg)))\n",
    "        mg = self.pool(F.relu(self.conv2_mg(mg))) #torch.Size([4, 8, 211, 282])\n",
    "        na = self.pool(F.relu(self.conv1_na(na)))\n",
    "        na = self.pool(F.relu(self.conv2_na(na))) #torch.Size([4, 8, 211, 282])\n",
    "        o = self.pool(F.relu(self.conv1_o(o)))\n",
    "        o = self.pool(F.relu(self.conv2_o(o))) #torch.Size([4, 8, 211, 282])\n",
    "        s = self.pool(F.relu(self.conv1_s(s)))\n",
    "        s = self.pool(F.relu(self.conv2_s(s))) #torch.Size([4, 8, 211, 282])\n",
    "        cl = self.pool(F.relu(self.conv1_cl(cl)))\n",
    "        cl = self.pool(F.relu(self.conv2_cl(cl))) #torch.Size([4, 8, 211, 282])\n",
    "        \n",
    "        return sem, c, ca, mg, na, o, s, cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df698b37-76f5-4642-b7ee-93a2638de1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extraction = _feature_extraction()\n",
    "# sem = torch.rand(4, 3, 1920, 2560)\n",
    "# c = torch.rand(4, 1, 1920, 2560)\n",
    "# ca = torch.rand(4, 1, 1920, 2560)\n",
    "# mg = torch.rand(4, 1, 1920, 2560)\n",
    "# na = torch.rand(4, 1, 1920, 2560)\n",
    "# o = torch.rand(4, 1, 1920, 2560)\n",
    "# s = torch.rand(4, 1, 1920, 2560)\n",
    "# cl = torch.rand(4, 1, 1920, 2560)\n",
    "\n",
    "# sem, c, ca, mg, na, o, s, cl = feature_extraction(sem, c, ca, mg, na, o, s, cl)\n",
    "# sem.shape # torch.Size([4, 8, 118, 158])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd958afe-9407-4c0d-b4e9-d467a0a47ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _cross_transformer(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(_cross_transformer, self).__init__()\n",
    "        \n",
    "        # self.transformer = Transformer(211, 7, 282, 3, 6)\n",
    "        self.transformer = Transformer(118, 7, 158, 3, 2)\n",
    "\n",
    "    def forward(self, sem, c, ca, mg, na, o, s, cl):\n",
    "        c_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        ca_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        mg_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        na_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        o_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        s_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        cl_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        \n",
    "        for i in range(sem.shape[0]):\n",
    "            \n",
    "            sem_i = sem[i]\n",
    "            c_i = c[i]\n",
    "            ca_i = ca[i]\n",
    "            mg_i = mg[i]\n",
    "            na_i = na[i]\n",
    "            o_i = o[i]\n",
    "            s_i = s[i]\n",
    "            cl_i = cl[i]\n",
    "            \n",
    "            c_sem = self.transformer(c_i, sem_i)\n",
    "            c_ca = self.transformer(c_i, ca_i)\n",
    "            c_mg = self.transformer(c_i, mg_i)\n",
    "            c_na = self.transformer(c_i, na_i)\n",
    "            c_o = self.transformer(c_i, o_i)\n",
    "            c_s = self.transformer(c_i, s_i)\n",
    "            c_cl = self.transformer(c_i, cl_i)\n",
    "            c_temp = torch.cat((c_sem, c_ca, c_mg, c_na, c_o, c_s, c_cl), 0)\n",
    "            \n",
    "            ca_sem = self.transformer(ca_i, sem_i)\n",
    "            ca_c = self.transformer(ca_i, c_i)\n",
    "            ca_mg = self.transformer(ca_i, mg_i)\n",
    "            ca_na = self.transformer(ca_i, na_i)\n",
    "            ca_o = self.transformer(ca_i, o_i)\n",
    "            ca_s = self.transformer(ca_i, s_i)\n",
    "            ca_cl = self.transformer(ca_i, cl_i)\n",
    "            ca_temp = torch.cat((ca_sem, ca_c, ca_mg, ca_na, ca_o, ca_s, ca_cl), 0)\n",
    "            \n",
    "            mg_sem = self.transformer(mg_i, sem_i)\n",
    "            mg_c = self.transformer(mg_i, c_i)\n",
    "            mg_ca = self.transformer(mg_i, ca_i)\n",
    "            mg_na = self.transformer(mg_i, na_i)\n",
    "            mg_o = self.transformer(mg_i, o_i)\n",
    "            mg_s = self.transformer(mg_i, s_i)\n",
    "            mg_cl = self.transformer(mg_i, cl_i)\n",
    "            mg_temp = torch.cat((mg_sem, mg_c, mg_ca, mg_na, mg_o, mg_s, mg_cl), 0)\n",
    "            \n",
    "            na_sem = self.transformer(na_i, sem_i)\n",
    "            na_c = self.transformer(na_i, c_i)\n",
    "            na_ca = self.transformer(na_i, ca_i)\n",
    "            na_mg = self.transformer(na_i, mg_i)\n",
    "            na_o = self.transformer(na_i, o_i)\n",
    "            na_s = self.transformer(na_i, s_i)\n",
    "            na_cl = self.transformer(na_i, cl_i)\n",
    "            na_temp = torch.cat((na_sem, na_c, na_ca, na_mg, na_o, na_s, na_cl), 0)\n",
    "            \n",
    "            o_sem = self.transformer(o_i, sem_i)\n",
    "            o_c = self.transformer(o_i, c_i)\n",
    "            o_ca = self.transformer(o_i, ca_i)\n",
    "            o_mg = self.transformer(o_i, mg_i)\n",
    "            o_na = self.transformer(o_i, na_i)\n",
    "            o_s = self.transformer(o_i, s_i)\n",
    "            o_cl = self.transformer(o_i, cl_i)\n",
    "            o_temp = torch.cat((o_sem, o_c, o_ca, o_mg, o_na, o_s, c_cl), 0)\n",
    "            \n",
    "            s_sem = self.transformer(s_i, sem_i)\n",
    "            s_c = self.transformer(s_i, c_i)\n",
    "            s_ca = self.transformer(s_i, ca_i)\n",
    "            s_mg = self.transformer(s_i, mg_i)\n",
    "            s_na = self.transformer(s_i, na_i)\n",
    "            s_o = self.transformer(s_i, o_i)\n",
    "            s_cl = self.transformer(s_i, cl_i)\n",
    "            s_temp = torch.cat((s_sem, s_c, s_ca, s_mg, s_na, s_o, s_cl), 0)\n",
    "            \n",
    "            cl_sem = self.transformer(cl_i, sem_i)\n",
    "            cl_c = self.transformer(cl_i, c_i)\n",
    "            cl_ca = self.transformer(cl_i, ca_i)\n",
    "            cl_mg = self.transformer(cl_i, mg_i)\n",
    "            cl_na = self.transformer(cl_i, na_i)\n",
    "            cl_o = self.transformer(cl_i, o_i)\n",
    "            cl_s = self.transformer(cl_i, s_i)\n",
    "            cl_temp = torch.cat((cl_sem, cl_c, cl_ca, cl_mg, cl_na, c_o, c_s), 0)\n",
    "            \n",
    "            c_temp = torch.reshape(c_temp, (1, 7))\n",
    "            ca_temp = torch.reshape(ca_temp, (1, 7))\n",
    "            mg_temp = torch.reshape(mg_temp, (1, 7))\n",
    "            na_temp = torch.reshape(na_temp, (1, 7))\n",
    "            o_temp = torch.reshape(o_temp, (1, 7))\n",
    "            s_temp = torch.reshape(s_temp, (1, 7))\n",
    "            cl_temp = torch.reshape(cl_temp, (1, 7))\n",
    "            \n",
    "            c_predict = torch.cat((c_predict, c_temp), 0)\n",
    "            ca_predict = torch.cat((ca_predict, ca_temp), 0)\n",
    "            mg_predict = torch.cat((mg_predict, mg_temp), 0)\n",
    "            na_predict = torch.cat((na_predict, na_temp), 0)\n",
    "            o_predict = torch.cat((o_predict, o_temp), 0)\n",
    "            s_predict = torch.cat((s_predict, s_temp), 0)\n",
    "            cl_predict = torch.cat((cl_predict, cl_temp), 0)\n",
    "        \n",
    "        c_predict = c_predict[1:]\n",
    "        ca_predict = ca_predict[1:]\n",
    "        mg_predict = mg_predict[1:]\n",
    "        na_predict = na_predict[1:]\n",
    "        o_predict = o_predict[1:]\n",
    "        s_predict = s_predict[1:]\n",
    "        cl_predict = cl_predict[1:]\n",
    "            \n",
    "        output = torch.cat((c_predict, ca_predict, mg_predict, na_predict, o_predict, s_predict, cl_predict), 1)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f90729bb-028e-4a55-bd64-f1cc19739657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_vocab = 118\n",
    "# trg_vocab = 7\n",
    "# t = _cross_transformer()\n",
    "# src = torch.randn(4, 8, 118, 158)\n",
    "\n",
    "# # t = t.to('cuda')\n",
    "# # src = src.to('cuda')\n",
    "\n",
    "# output = t(src, src, src, src, src, src, src, src)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70fa4391-5634-490a-9fa6-8267d90bd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.get_layers = _get_layers(7)\n",
    "        self.feature_extraction = _feature_extraction()\n",
    "        # src_vocab = 211\n",
    "        # trg_vocab = 7\n",
    "        self._cross_transformer = _cross_transformer(device)\n",
    "        self.out = nn.Linear(49, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        sem, c, ca, mg, na, o, s, cl = self.get_layers(x)\n",
    "        sem, c, ca, mg, na, o, s, cl = self.feature_extraction(sem, c, ca, mg, na, o, s, cl)\n",
    "        output = self._cross_transformer(sem, c, ca, mg, na, o, s, cl)\n",
    "        # output = output.to('cuda')\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5ba3d4e-cbee-456d-bd7f-ab306b095154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheModelClass(\n",
      "  (get_layers): _get_layers()\n",
      "  (feature_extraction): _feature_extraction(\n",
      "    (pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv1_sem): Conv2d(3, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2_sem): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv1_c): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2_c): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv1_ca): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2_ca): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv1_mg): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2_mg): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv1_na): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2_na): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv1_o): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2_o): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv1_s): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2_s): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv1_cl): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2_cl): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "  )\n",
      "  (_cross_transformer): _cross_transformer(\n",
      "    (transformer): Transformer(\n",
      "      (encoder): Encoder(\n",
      "        (pe): PositionalEncoder()\n",
      "        (layers): ModuleList(\n",
      "          (0): EncoderLayer(\n",
      "            (norm_1): Norm()\n",
      "            (norm_2): Norm()\n",
      "            (attn): MultiHeadAttention(\n",
      "              (q_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (v_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (k_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (out): Linear(in_features=158, out_features=158, bias=True)\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (linear_1): Linear(in_features=158, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear_2): Linear(in_features=2048, out_features=158, bias=True)\n",
      "            )\n",
      "            (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): EncoderLayer(\n",
      "            (norm_1): Norm()\n",
      "            (norm_2): Norm()\n",
      "            (attn): MultiHeadAttention(\n",
      "              (q_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (v_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (k_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (out): Linear(in_features=158, out_features=158, bias=True)\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (linear_1): Linear(in_features=158, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear_2): Linear(in_features=2048, out_features=158, bias=True)\n",
      "            )\n",
      "            (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): EncoderLayer(\n",
      "            (norm_1): Norm()\n",
      "            (norm_2): Norm()\n",
      "            (attn): MultiHeadAttention(\n",
      "              (q_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (v_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (k_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (out): Linear(in_features=158, out_features=158, bias=True)\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (linear_1): Linear(in_features=158, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear_2): Linear(in_features=2048, out_features=158, bias=True)\n",
      "            )\n",
      "            (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (norm): Norm()\n",
      "      )\n",
      "      (decoder): Decoder(\n",
      "        (pe): PositionalEncoder()\n",
      "        (layers): ModuleList(\n",
      "          (0): DecoderLayer(\n",
      "            (norm_1): Norm()\n",
      "            (norm_2): Norm()\n",
      "            (norm_3): Norm()\n",
      "            (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout_3): Dropout(p=0.1, inplace=False)\n",
      "            (attn_1): MultiHeadAttention(\n",
      "              (q_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (v_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (k_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (out): Linear(in_features=158, out_features=158, bias=True)\n",
      "            )\n",
      "            (attn_2): MultiHeadAttention(\n",
      "              (q_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (v_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (k_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (out): Linear(in_features=158, out_features=158, bias=True)\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (linear_1): Linear(in_features=158, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear_2): Linear(in_features=2048, out_features=158, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (1): DecoderLayer(\n",
      "            (norm_1): Norm()\n",
      "            (norm_2): Norm()\n",
      "            (norm_3): Norm()\n",
      "            (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout_3): Dropout(p=0.1, inplace=False)\n",
      "            (attn_1): MultiHeadAttention(\n",
      "              (q_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (v_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (k_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (out): Linear(in_features=158, out_features=158, bias=True)\n",
      "            )\n",
      "            (attn_2): MultiHeadAttention(\n",
      "              (q_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (v_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (k_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (out): Linear(in_features=158, out_features=158, bias=True)\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (linear_1): Linear(in_features=158, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear_2): Linear(in_features=2048, out_features=158, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (2): DecoderLayer(\n",
      "            (norm_1): Norm()\n",
      "            (norm_2): Norm()\n",
      "            (norm_3): Norm()\n",
      "            (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "            (dropout_3): Dropout(p=0.1, inplace=False)\n",
      "            (attn_1): MultiHeadAttention(\n",
      "              (q_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (v_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (k_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (out): Linear(in_features=158, out_features=158, bias=True)\n",
      "            )\n",
      "            (attn_2): MultiHeadAttention(\n",
      "              (q_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (v_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (k_linear): Linear(in_features=158, out_features=158, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (out): Linear(in_features=158, out_features=158, bias=True)\n",
      "            )\n",
      "            (ff): FeedForward(\n",
      "              (linear_1): Linear(in_features=158, out_features=2048, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear_2): Linear(in_features=2048, out_features=158, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (norm): Norm()\n",
      "      )\n",
      "      (reduce): Linear(in_features=158, out_features=7, bias=True)\n",
      "      (linear_1): Linear(in_features=826, out_features=7, bias=True)\n",
      "      (out): Linear(in_features=56, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out): Linear(in_features=49, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model_regression = TheModelClass(device)\n",
    "model_regression = model_regression.to(device)\n",
    "print(model_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ca0a521-7aea-415c-b456-035e5df3d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source, targets = next(iter(dataloader))\n",
    "# source = source.to('cuda')\n",
    "# targets = targets.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1bd3c3c-81d5-49d8-963f-91c0d4e3e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat = model_regression(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4e7de85-8efa-41da-8c74-11deb4437c08",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b953b4214890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rnn_torchviz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/graphviz/_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                               category=category)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/graphviz/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mrendered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/graphviz/_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                               category=category)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/graphviz/backend/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0mcmd\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     execute.run_check(cmd,\n\u001b[0m\u001b[1;32m    325\u001b[0m                       \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                       \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1866\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   1867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1868\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1869\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make_dot(yhat, params=dit(list(model_regression.named_parameters()))).render(\"vision_transformer_torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0afde5-2d7f-4a85-809d-c06ab6bb1392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model_regression.parameters(), lr=1e-3)\n",
    "loss_func = nn.MSELoss()\n",
    "# dataloader = DataLoader(\n",
    "#     dataset,\n",
    "#     batch_size=4,\n",
    "#     shuffle=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712087c-9089-41ef-a026-8ecd3af645f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffac99a4-f7b3-4da0-8f02-61509c872c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 19:34:31 | Epoch 0 | Loss: 84.04583740234375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0b28d29eb2d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 1000):\n",
    "    total_loss = 0\n",
    "    for source, targets in dataloader:\n",
    "        source = source.to('cuda')\n",
    "        targets = targets.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model_regression(source)\n",
    "        loss = loss_func(output, targets)\n",
    "        total_loss = total_loss + loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_list.append(total_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model_regression, 'regression_model.pth')\n",
    "    if epoch % 20 == 0:\n",
    "        # total_loss = run_test(model_regression, dataloader)\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Current Time = {current_time} | Epoch {epoch} | Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0309755-39b3-40fb-a8d5-ae2a1eec9182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
