{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552215b4-738d-475c-84ee-9a45a23bdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from utils import MyTrainDataset\n",
    "from datetime import datetime\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd4e46f-abdd-4fb3-83fa-407fd4050b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, elements):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_files = os.listdir(data_dir)\n",
    "        self.data_files.sort()\n",
    "        if self.data_files[0].startswith('.'):\n",
    "            self.data_files.pop(0)\n",
    "        \n",
    "        self.elements = np.load(elements)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.data_dir + '/' + self.data_files[idx]) # (1920, 2560, 10)\n",
    "        data = data/255\n",
    "        data = np.transpose(data, (2, 0, 1))\n",
    "        elements = self.elements[idx]\n",
    "        elements = np.float32(elements)\n",
    "        return torch.tensor(data), torch.tensor(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64c69e7-4280-40f6-aec3-14335e9af790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1920, 2560])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset('EDS_predict_path', 'elements.npy')\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(dataset[0][0].shape)\n",
    "print(dataset[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90e0db3-9b4f-498a-99b5-b7d5ce21c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _get_layers(nn.Module):\n",
    "    def __init__(self, elements=7):\n",
    "        super().__init__()\n",
    "        self.elements = elements\n",
    "    def forward(self, x):\n",
    "        sem = x[:, :3, :, :]\n",
    "        c = x[:, 3, :, :]\n",
    "        c = c[:, None, :, :] \n",
    "        ca = x[:, 4, :, :]\n",
    "        ca = ca[:, None, :, :]\n",
    "        mg = x[:, 5, :, :]\n",
    "        mg = mg[:, None, :, :]\n",
    "        na = x[:, 6, :, :]\n",
    "        na = na[:, None, :, :]\n",
    "        o = x[:, 7, :, :]\n",
    "        o = o[:, None, :, :]\n",
    "        s = x[:, 8, :, :]\n",
    "        s = s[:, None, :, :]\n",
    "        cl = x[:, 9, :, :]\n",
    "        cl = cl[:, None, :, :]\n",
    "        return sem, c, ca, mg, na, o, s, cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522ec478-6463-43a4-b573-4d027e7677e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4356122d-1df4-40c2-83b8-389bc6016dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \n",
    "        bs = q.size(0)\n",
    "        # a = self.q_linear(q)\n",
    "        # print(a.shape)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # print(q.shape)\n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "       \n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        \n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
    "        \n",
    "        output = self.out(concat)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9daa3431-b63d-4f21-a0fb-39023b9e6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_model = 158\n",
    "# heads = 2\n",
    "# x = torch.randn(8, 118, 158)\n",
    "# net = MultiHeadAttention(2, 158)\n",
    "# output = net(x, x, x)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f42487-3e89-41c1-a550-d9d09c5947b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
    "        super().__init__() \n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "# net = FeedForward(158)\n",
    "# x=torch.randn(10, 158)\n",
    "# y = net(x)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca1f76e4-eb50-4b01-ad33-a1bb14bde894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.size = d_model\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm\n",
    "    \n",
    "# net = Norm(158)\n",
    "# x=torch.randn(10, 158)\n",
    "# y = net(x\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0552a982-3dd2-46b0-99eb-f3d74dc4cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an encoder layer with one multi-head attention layer and one # feed-forward layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "# build a decoder layer with two multi-head attention layers and\n",
    "# one feed-forward layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "    def forward(self, x, e_outputs, src_mask=None, trg_mask=None):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x\n",
    "\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9013c7f7-abbb-4624-b8a3-4db1f0c52490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 300):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                \n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:,:seq_len], requires_grad=False)\n",
    "        return x\n",
    "\n",
    "# net = PositionalEncoder(282)\n",
    "# x = src = torch.randn(8, 211, 282)\n",
    "# y = net(x)\n",
    "# y.shape\n",
    "\n",
    "# net = PositionalEncoder(158)\n",
    "# x = src = torch.randn(8, 118, 158)\n",
    "# y = net(x)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b61527-3ff8-4b9c-86a4-adad4ee10aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        # self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, src, mask=None):\n",
    "        # x = self.embed(src)\n",
    "        x = src\n",
    "        # x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        # self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, trg, e_outputs, src_mask=None, trg_mask=None):\n",
    "        # x = self.embed(trg)\n",
    "        # x = self.pe(x)\n",
    "        x = trg\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e61689-ecc6-4b06-9ac1-52ed297ba612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
    "        self.reduce = nn.Linear(d_model, trg_vocab)\n",
    "        # self.reduce = nn.Linear(d_model, 1)\n",
    "        self.linear_1 = nn.Linear(trg_vocab*src_vocab, trg_vocab)\n",
    "        self.out = nn.Linear(56, 1)\n",
    "    def forward(self, src, trg, src_mask=None, trg_mask=None):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.reduce(d_output)\n",
    "        output = output.view(output.shape[0], -1)        \n",
    "        output = self.linear_1(output)\n",
    "        output = output.view(-1)\n",
    "        output = self.out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5476ffac-03cd-4d04-88c8-8db0cc9cf1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 118\n",
    "trg_vocab = 7\n",
    "# t = Transformer(src_vocab, trg_vocab, 158, 3, 2)\n",
    "# src = torch.randn(8, 118, 158)\n",
    "# trg = torch.randn(8, 118, 158)\n",
    "# # t = t.to('cuda')\n",
    "# # src = src.to('cuda')\n",
    "# # trg = trg.to('cuda')\n",
    "# output = t(src, trg)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfb1e10f-2803-4bff-886c-2b3195aa232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _feature_extraction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_feature_extraction, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.conv1_sem = nn.Conv2d(3, 4, 5)\n",
    "        self.conv2_sem = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_c = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_c = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_ca = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_ca = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_mg = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_mg = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_na = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_na = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_o = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_o = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_s = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_s = nn.Conv2d(4, 8, 5)\n",
    "        self.conv1_cl = nn.Conv2d(1, 4, 5)\n",
    "        self.conv2_cl = nn.Conv2d(4, 8, 5)\n",
    "    def forward(self, sem, c, ca, mg, na, o, s, cl):\n",
    "        sem = self.pool(F.relu(self.conv1_sem(sem)))\n",
    "        sem = self.pool(F.relu(self.conv2_sem(sem))) #torch.Size([4, 8, 211, 282])\n",
    "        c = self.pool(F.relu(self.conv1_c(c)))\n",
    "        c = self.pool(F.relu(self.conv2_c(c))) #torch.Size([4, 8, 211, 282])\n",
    "        ca = self.pool(F.relu(self.conv1_ca(ca)))\n",
    "        ca = self.pool(F.relu(self.conv2_ca(ca))) #torch.Size([4, 8, 211, 282])\n",
    "        mg = self.pool(F.relu(self.conv1_mg(mg)))\n",
    "        mg = self.pool(F.relu(self.conv2_mg(mg))) #torch.Size([4, 8, 211, 282])\n",
    "        na = self.pool(F.relu(self.conv1_na(na)))\n",
    "        na = self.pool(F.relu(self.conv2_na(na))) #torch.Size([4, 8, 211, 282])\n",
    "        o = self.pool(F.relu(self.conv1_o(o)))\n",
    "        o = self.pool(F.relu(self.conv2_o(o))) #torch.Size([4, 8, 211, 282])\n",
    "        s = self.pool(F.relu(self.conv1_s(s)))\n",
    "        s = self.pool(F.relu(self.conv2_s(s))) #torch.Size([4, 8, 211, 282])\n",
    "        cl = self.pool(F.relu(self.conv1_cl(cl)))\n",
    "        cl = self.pool(F.relu(self.conv2_cl(cl))) #torch.Size([4, 8, 211, 282])\n",
    "        \n",
    "        return sem, c, ca, mg, na, o, s, cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df698b37-76f5-4642-b7ee-93a2638de1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extraction = _feature_extraction()\n",
    "# sem = torch.rand(4, 3, 1920, 2560)\n",
    "# c = torch.rand(4, 1, 1920, 2560)\n",
    "# ca = torch.rand(4, 1, 1920, 2560)\n",
    "# mg = torch.rand(4, 1, 1920, 2560)\n",
    "# na = torch.rand(4, 1, 1920, 2560)\n",
    "# o = torch.rand(4, 1, 1920, 2560)\n",
    "# s = torch.rand(4, 1, 1920, 2560)\n",
    "# cl = torch.rand(4, 1, 1920, 2560)\n",
    "\n",
    "# sem, c, ca, mg, na, o, s, cl = feature_extraction(sem, c, ca, mg, na, o, s, cl)\n",
    "# sem.shape # torch.Size([4, 8, 118, 158])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd958afe-9407-4c0d-b4e9-d467a0a47ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _cross_transformer(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(_cross_transformer, self).__init__()\n",
    "        \n",
    "        # self.transformer = Transformer(211, 7, 282, 3, 6)\n",
    "        self.transformer = Transformer(118, 7, 158, 3, 2)\n",
    "\n",
    "    def forward(self, sem, c, ca, mg, na, o, s, cl):\n",
    "        c_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        ca_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        mg_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        na_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        o_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        s_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        cl_predict = torch.empty((1,7), dtype=torch.float32).to(device)\n",
    "        \n",
    "        for i in range(sem.shape[0]):\n",
    "            \n",
    "            sem_i = sem[i]\n",
    "            c_i = c[i]\n",
    "            ca_i = ca[i]\n",
    "            mg_i = mg[i]\n",
    "            na_i = na[i]\n",
    "            o_i = o[i]\n",
    "            s_i = s[i]\n",
    "            cl_i = cl[i]\n",
    "            \n",
    "            c_sem = self.transformer(c_i, sem_i)\n",
    "            c_ca = self.transformer(c_i, ca_i)\n",
    "            c_mg = self.transformer(c_i, mg_i)\n",
    "            c_na = self.transformer(c_i, na_i)\n",
    "            c_o = self.transformer(c_i, o_i)\n",
    "            c_s = self.transformer(c_i, s_i)\n",
    "            c_cl = self.transformer(c_i, cl_i)\n",
    "            c_temp = torch.cat((c_sem, c_ca, c_mg, c_na, c_o, c_s, c_cl), 0)\n",
    "            \n",
    "            ca_sem = self.transformer(ca_i, sem_i)\n",
    "            ca_c = self.transformer(ca_i, c_i)\n",
    "            ca_mg = self.transformer(ca_i, mg_i)\n",
    "            ca_na = self.transformer(ca_i, na_i)\n",
    "            ca_o = self.transformer(ca_i, o_i)\n",
    "            ca_s = self.transformer(ca_i, s_i)\n",
    "            ca_cl = self.transformer(ca_i, cl_i)\n",
    "            ca_temp = torch.cat((ca_sem, ca_c, ca_mg, ca_na, ca_o, ca_s, ca_cl), 0)\n",
    "            \n",
    "            mg_sem = self.transformer(mg_i, sem_i)\n",
    "            mg_c = self.transformer(mg_i, c_i)\n",
    "            mg_ca = self.transformer(mg_i, ca_i)\n",
    "            mg_na = self.transformer(mg_i, na_i)\n",
    "            mg_o = self.transformer(mg_i, o_i)\n",
    "            mg_s = self.transformer(mg_i, s_i)\n",
    "            mg_cl = self.transformer(mg_i, cl_i)\n",
    "            mg_temp = torch.cat((mg_sem, mg_c, mg_ca, mg_na, mg_o, mg_s, mg_cl), 0)\n",
    "            \n",
    "            na_sem = self.transformer(na_i, sem_i)\n",
    "            na_c = self.transformer(na_i, c_i)\n",
    "            na_ca = self.transformer(na_i, ca_i)\n",
    "            na_mg = self.transformer(na_i, mg_i)\n",
    "            na_o = self.transformer(na_i, o_i)\n",
    "            na_s = self.transformer(na_i, s_i)\n",
    "            na_cl = self.transformer(na_i, cl_i)\n",
    "            na_temp = torch.cat((na_sem, na_c, na_ca, na_mg, na_o, na_s, na_cl), 0)\n",
    "            \n",
    "            o_sem = self.transformer(o_i, sem_i)\n",
    "            o_c = self.transformer(o_i, c_i)\n",
    "            o_ca = self.transformer(o_i, ca_i)\n",
    "            o_mg = self.transformer(o_i, mg_i)\n",
    "            o_na = self.transformer(o_i, na_i)\n",
    "            o_s = self.transformer(o_i, s_i)\n",
    "            o_cl = self.transformer(o_i, cl_i)\n",
    "            o_temp = torch.cat((o_sem, o_c, o_ca, o_mg, o_na, o_s, c_cl), 0)\n",
    "            \n",
    "            s_sem = self.transformer(s_i, sem_i)\n",
    "            s_c = self.transformer(s_i, c_i)\n",
    "            s_ca = self.transformer(s_i, ca_i)\n",
    "            s_mg = self.transformer(s_i, mg_i)\n",
    "            s_na = self.transformer(s_i, na_i)\n",
    "            s_o = self.transformer(s_i, o_i)\n",
    "            s_cl = self.transformer(s_i, cl_i)\n",
    "            s_temp = torch.cat((s_sem, s_c, s_ca, s_mg, s_na, s_o, s_cl), 0)\n",
    "            \n",
    "            cl_sem = self.transformer(cl_i, sem_i)\n",
    "            cl_c = self.transformer(cl_i, c_i)\n",
    "            cl_ca = self.transformer(cl_i, ca_i)\n",
    "            cl_mg = self.transformer(cl_i, mg_i)\n",
    "            cl_na = self.transformer(cl_i, na_i)\n",
    "            cl_o = self.transformer(cl_i, o_i)\n",
    "            cl_s = self.transformer(cl_i, s_i)\n",
    "            cl_temp = torch.cat((cl_sem, cl_c, cl_ca, cl_mg, cl_na, c_o, c_s), 0)\n",
    "            \n",
    "            c_temp = torch.reshape(c_temp, (1, 7))\n",
    "            ca_temp = torch.reshape(ca_temp, (1, 7))\n",
    "            mg_temp = torch.reshape(mg_temp, (1, 7))\n",
    "            na_temp = torch.reshape(na_temp, (1, 7))\n",
    "            o_temp = torch.reshape(o_temp, (1, 7))\n",
    "            s_temp = torch.reshape(s_temp, (1, 7))\n",
    "            cl_temp = torch.reshape(cl_temp, (1, 7))\n",
    "            \n",
    "            c_predict = torch.cat((c_predict, c_temp), 0)\n",
    "            ca_predict = torch.cat((ca_predict, ca_temp), 0)\n",
    "            mg_predict = torch.cat((mg_predict, mg_temp), 0)\n",
    "            na_predict = torch.cat((na_predict, na_temp), 0)\n",
    "            o_predict = torch.cat((o_predict, o_temp), 0)\n",
    "            s_predict = torch.cat((s_predict, s_temp), 0)\n",
    "            cl_predict = torch.cat((cl_predict, cl_temp), 0)\n",
    "        \n",
    "        c_predict = c_predict[1:]\n",
    "        ca_predict = ca_predict[1:]\n",
    "        mg_predict = mg_predict[1:]\n",
    "        na_predict = na_predict[1:]\n",
    "        o_predict = o_predict[1:]\n",
    "        s_predict = s_predict[1:]\n",
    "        cl_predict = cl_predict[1:]\n",
    "            \n",
    "        output = torch.cat((c_predict, ca_predict, mg_predict, na_predict, o_predict, s_predict, cl_predict), 1)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f90729bb-028e-4a55-bd64-f1cc19739657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_vocab = 118\n",
    "# trg_vocab = 7\n",
    "# t = _cross_transformer()\n",
    "# src = torch.randn(4, 8, 118, 158)\n",
    "\n",
    "# # t = t.to('cuda')\n",
    "# # src = src.to('cuda')\n",
    "\n",
    "# output = t(src, src, src, src, src, src, src, src)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70fa4391-5634-490a-9fa6-8267d90bd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.get_layers = _get_layers(7)\n",
    "        self.feature_extraction = _feature_extraction()\n",
    "        # src_vocab = 211\n",
    "        # trg_vocab = 7\n",
    "        self._cross_transformer = _cross_transformer(device)\n",
    "        self.out = nn.Linear(49, 7)\n",
    "        self.sigma = nn.Linear(7, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        sem, c, ca, mg, na, o, s, cl = self.get_layers(x)\n",
    "        sem, c, ca, mg, na, o, s, cl = self.feature_extraction(sem, c, ca, mg, na, o, s, cl)\n",
    "        output = self._cross_transformer(sem, c, ca, mg, na, o, s, cl)\n",
    "        # output = output.to('cuda')\n",
    "        output = self.out(output)\n",
    "        sigma = self.sigma(output)\n",
    "        \n",
    "        return output, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5ba3d4e-cbee-456d-bd7f-ab306b095154",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model_regression = TheModelClass(device)\n",
    "model_regression = model_regression.to(device)\n",
    "# print(model_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3389e890-df6e-431c-b1c2-c293715908de",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model_regression.parameters(), lr=1e-3)\n",
    "loss_func = nn.MSELoss()\n",
    "total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ca0a521-7aea-415c-b456-035e5df3d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source, targets = next(iter(dataloader))\n",
    "# source = source.to('cuda')\n",
    "# targets = targets.to('cuda')\n",
    "# yhat = model_regression(source)\n",
    "# make_dot(yhat, params=dit(list(model_regression.named_parameters()))).render(\"vision_transformer_torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d0afde5-2d7f-4a85-809d-c06ab6bb1392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model_regression.parameters(), lr=1e-3)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d79b64ff-2196-4eab-8f7e-a639c1e72d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = torch.from_numpy(np.zeros((4, 7)))\n",
    "standard = standard.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17bb24-4235-4d61-a284-8cb57f33f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac99a4-f7b3-4da0-8f02-61509c872c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 00:58:23 | Epoch 0 | Loss: 977.1055371575058\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 1000):\n",
    "    total_loss = 0\n",
    "    for source, targets in dataloader:\n",
    "        source = source.to('cuda')\n",
    "        targets = targets.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output, sigma = model_regression(source)\n",
    "        diff = torch.abs(output-targets)-sigma\n",
    "        loss = torch.sum(torch.max(diff, standard))\n",
    "        total_loss = total_loss + loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_list.append(total_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model_regression, 'regression_model.pth')\n",
    "    if epoch % 20 == 0:\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Current Time = {current_time} | Epoch {epoch} | Loss: {total_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
